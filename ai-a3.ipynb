{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "514dee18",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-23T08:17:24.087311Z",
     "iopub.status.busy": "2024-10-23T08:17:24.086383Z",
     "iopub.status.idle": "2024-10-23T08:17:26.102430Z",
     "shell.execute_reply": "2024-10-23T08:17:26.101404Z"
    },
    "papermill": {
     "duration": 2.024165,
     "end_time": "2024-10-23T08:17:26.104783",
     "exception": false,
     "start_time": "2024-10-23T08:17:24.080618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp /kaggle/input/setupfiles/environment.yml /kaggle/working/\n",
    "!cp /kaggle/input/setupfiles/install.sh /kaggle/working/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae241667",
   "metadata": {
    "papermill": {
     "duration": 0.003392,
     "end_time": "2024-10-23T08:17:26.112405",
     "exception": false,
     "start_time": "2024-10-23T08:17:26.109013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dependency Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "208c3857",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T08:17:26.121089Z",
     "iopub.status.busy": "2024-10-23T08:17:26.120745Z",
     "iopub.status.idle": "2024-10-23T08:17:39.638978Z",
     "shell.execute_reply": "2024-10-23T08:17:39.638003Z"
    },
    "papermill": {
     "duration": 13.525285,
     "end_time": "2024-10-23T08:17:39.641219",
     "exception": false,
     "start_time": "2024-10-23T08:17:26.115934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies from environment.yml using pip...\r\n",
      "Environment setup completed successfully!\r\n"
     ]
    }
   ],
   "source": [
    "!bash install.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fe3d8c",
   "metadata": {
    "papermill": {
     "duration": 0.003501,
     "end_time": "2024-10-23T08:17:39.648625",
     "exception": false,
     "start_time": "2024-10-23T08:17:39.645124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a89f8f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T08:17:39.657204Z",
     "iopub.status.busy": "2024-10-23T08:17:39.656880Z",
     "iopub.status.idle": "2024-10-23T08:17:49.060872Z",
     "shell.execute_reply": "2024-10-23T08:17:49.059951Z"
    },
    "papermill": {
     "duration": 9.411019,
     "end_time": "2024-10-23T08:17:49.063245",
     "exception": false,
     "start_time": "2024-10-23T08:17:39.652226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b8b56",
   "metadata": {
    "papermill": {
     "duration": 0.00352,
     "end_time": "2024-10-23T08:17:49.070602",
     "exception": false,
     "start_time": "2024-10-23T08:17:49.067082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Class Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3551f07a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T08:17:49.080660Z",
     "iopub.status.busy": "2024-10-23T08:17:49.080242Z",
     "iopub.status.idle": "2024-10-23T08:17:49.109361Z",
     "shell.execute_reply": "2024-10-23T08:17:49.108640Z"
    },
    "papermill": {
     "duration": 0.03728,
     "end_time": "2024-10-23T08:17:49.111458",
     "exception": false,
     "start_time": "2024-10-23T08:17:49.074178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class birdClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(birdClassifier, self).__init__()\n",
    "        print(\"Initializing birdClassifier\")\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  # Conv1: 64 filters\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),  # Conv2: 64 filters\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Pooling reduces size by half\n",
    "            # Block 2\n",
    "            nn.Conv2d(\n",
    "                64, 128, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv3: 128 filters\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                128, 128, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv4: 128 filters\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Block 3\n",
    "            nn.Conv2d(\n",
    "                128, 256, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv5: 256 filters\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                256, 256, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv6: 256 filters\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                256, 256, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv7: 256 filters\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Block 4\n",
    "            nn.Conv2d(\n",
    "                256, 512, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv8: 512 filters\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                512, 512, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv9: 512 filters\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                512, 512, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv10: 512 filters\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Block 5\n",
    "            nn.Conv2d(\n",
    "                512, 1024, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv11: 1024 filters\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                1024, 1024, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv12: 1024 filters\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024 * 7 * 7, 4096),  # Fully connected layer 1\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Dropout for regularization\n",
    "            nn.Linear(4096, 4096),  # Fully connected layer 2\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 10))  # Output layer (10 bird classes))\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction=\"none\")\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=60,\n",
    "    patience=10,\n",
    "):\n",
    "    print(\"Starting model training\")\n",
    "    model.train()\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_without_improvement = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 100 == 99:  # Print every 100 mini-batches\n",
    "                print(\n",
    "                    f\"[Epoch {epoch + 1}, Batch {i + 1}] Loss: {running_loss / 100:.6f}\"\n",
    "                )\n",
    "                print(f\"Sample outputs: {outputs[0][:5]}\")\n",
    "                print(f\"Sample labels: {labels[0]}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Epoch {epoch + 1} Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             epochs_without_improvement = 0\n",
    "#             best_model_state = model.state_dict()\n",
    "#         else:\n",
    "#             epochs_without_improvement += 1\n",
    "#             if epochs_without_improvement >= patience:\n",
    "#                 print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "#                 model.load_state_dict(best_model_state)\n",
    "#                 break\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89487881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T08:17:49.119840Z",
     "iopub.status.busy": "2024-10-23T08:17:49.119532Z",
     "iopub.status.idle": "2024-10-23T08:19:06.330047Z",
     "shell.execute_reply": "2024-10-23T08:19:06.328834Z"
    },
    "papermill": {
     "duration": 77.217565,
     "end_time": "2024-10-23T08:19:06.332572",
     "exception": false,
     "start_time": "2024-10-23T08:17:49.115007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script started\n",
      "Data path: /kaggle/input/identify-the-birds/Birds/train\n",
      "Train status: train\n",
      "Model path: --HistoryManager.hist_file=:memory:\n",
      "Entering training mode\n",
      "Label distribution: {3: 541, 6: 776, 5: 765, 2: 453, 7: 615, 8: 602, 0: 714, 9: 524, 4: 779, 1: 605}\n",
      "Input data range: [0.00, 1.00]\n"
     ]
    }
   ],
   "source": [
    "print(\"Script started\")\n",
    "dataPath = \"/kaggle/input/identify-the-birds/Birds/train\"\n",
    "trainStatus = \"train\"\n",
    "modelPath = sys.argv[3] if len(sys.argv) > 3 else \"model.pth\"\n",
    "\n",
    "print(f\"Data path: {dataPath}\")\n",
    "print(f\"Train status: {trainStatus}\")\n",
    "print(f\"Model path: {modelPath}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Entering training mode\")\n",
    "\n",
    "# Set up data transformations\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "full_dataset = datasets.ImageFolder(root=dataPath, transform=transform)\n",
    "\n",
    "# Create train-test split\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(full_dataset)),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=full_dataset.targets,\n",
    ")\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "label_counts = {}\n",
    "for _, labels in train_loader:\n",
    "    for label in labels:\n",
    "        label_counts[label.item()] = label_counts.get(label.item(), 0) + 1\n",
    "print(\"Label distribution:\", label_counts)\n",
    "\n",
    "\n",
    "# Check input data range\n",
    "for inputs, labels in train_loader:\n",
    "    print(f\"Input data range: [{inputs.min().item():.2f}, {inputs.max().item():.2f}]\")\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a6a61",
   "metadata": {
    "papermill": {
     "duration": 0.003627,
     "end_time": "2024-10-23T08:19:06.340291",
     "exception": false,
     "start_time": "2024-10-23T08:19:06.336664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Run your .py file on CLI using the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21334087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T08:19:06.349696Z",
     "iopub.status.busy": "2024-10-23T08:19:06.349324Z",
     "iopub.status.idle": "2024-10-23T09:36:59.154165Z",
     "shell.execute_reply": "2024-10-23T09:36:59.152997Z"
    },
    "papermill": {
     "duration": 4672.82986,
     "end_time": "2024-10-23T09:36:59.174047",
     "exception": false,
     "start_time": "2024-10-23T08:19:06.344187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing birdClassifier\n",
      "Model created and moved to device\n",
      "Starting model training\n",
      "[Epoch 1, Batch 100] Loss: 5.141156\n",
      "Sample outputs: tensor([ 0.2176, -1.2889,  1.3896,  0.8457,  1.3572], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 1, Batch 200] Loss: 3.720426\n",
      "Sample outputs: tensor([ 0.6002, -3.6493,  5.4599,  4.3523,  7.9294], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "Epoch 1 Validation Loss: 3.899921\n",
      "[Epoch 2, Batch 100] Loss: 3.279311\n",
      "Sample outputs: tensor([ 0.8013, -1.9294,  0.7886,  0.9917,  1.4307], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 2, Batch 200] Loss: 3.095526\n",
      "Sample outputs: tensor([  0.3107, -10.0213,   6.4071,  -0.9423,   4.1829], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "Epoch 2 Validation Loss: 1.329412\n",
      "[Epoch 3, Batch 100] Loss: 3.354533\n",
      "Sample outputs: tensor([ 0.9735, -2.8167,  2.1971,  2.6162,  3.9307], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 3, Batch 200] Loss: 2.619936\n",
      "Sample outputs: tensor([ 1.4924, -4.8682,  2.5257,  1.6247,  2.5031], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "Epoch 3 Validation Loss: 1.445577\n",
      "[Epoch 4, Batch 100] Loss: 2.973751\n",
      "Sample outputs: tensor([-2.6652,  3.8736, -3.1653, -3.2731, -2.9396], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 4, Batch 200] Loss: 2.768020\n",
      "Sample outputs: tensor([ 0.9000, -1.3259,  0.4571,  0.5884,  1.7152], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "Epoch 4 Validation Loss: 2.347237\n",
      "[Epoch 5, Batch 100] Loss: 2.602035\n",
      "Sample outputs: tensor([ 0.1625, -1.5122,  0.3926,  1.7217,  0.6780], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 5, Batch 200] Loss: 2.398276\n",
      "Sample outputs: tensor([ 1.2706, -3.3191, -0.0693,  1.3080, -0.5754], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "Epoch 5 Validation Loss: 4.680893\n",
      "[Epoch 6, Batch 100] Loss: 2.220920\n",
      "Sample outputs: tensor([-3.1897,  2.7439, -3.3789, -3.8052, -4.5743], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 6, Batch 200] Loss: 2.399936\n",
      "Sample outputs: tensor([ 2.0482, -2.6630,  0.0425,  1.0641,  0.5685], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "Epoch 6 Validation Loss: 2.384849\n",
      "[Epoch 7, Batch 100] Loss: 2.012651\n",
      "Sample outputs: tensor([ 0.2879, -1.4689,  0.4155,  0.0875,  0.9957], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 7, Batch 200] Loss: 1.776439\n",
      "Sample outputs: tensor([ 4.3607, -2.1409, -0.5207, -0.5292, -1.0900], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "Epoch 7 Validation Loss: 1.889604\n",
      "[Epoch 8, Batch 100] Loss: 1.789489\n",
      "Sample outputs: tensor([-3.3039,  2.0185, -3.1685, -4.0100, -3.6696], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 8, Batch 200] Loss: 1.553512\n",
      "Sample outputs: tensor([ 0.4448, -3.6237,  0.2702,  1.6933,  1.0356], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "Epoch 8 Validation Loss: 1.402912\n",
      "[Epoch 9, Batch 100] Loss: 1.531669\n",
      "Sample outputs: tensor([-1.8768,  1.0291, -0.7360, -1.9188, -1.4206], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 9, Batch 200] Loss: 1.516196\n",
      "Sample outputs: tensor([ 4.4016, -3.4378,  1.5361, -0.5925, -1.7705], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "Epoch 9 Validation Loss: 1.892341\n",
      "[Epoch 10, Batch 100] Loss: 1.491305\n",
      "Sample outputs: tensor([ 2.1326, -1.0715, -0.3810, -1.4693,  0.1902], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 10, Batch 200] Loss: 1.380457\n",
      "Sample outputs: tensor([ 0.6276, -0.2232,  0.2321, -3.4761,  0.1148], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "Epoch 10 Validation Loss: 1.608509\n",
      "[Epoch 11, Batch 100] Loss: 1.196406\n",
      "Sample outputs: tensor([ 2.8458, -2.1820, -1.0570, -0.9575, -0.7158], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 11, Batch 200] Loss: 1.108298\n",
      "Sample outputs: tensor([-4.9766,  4.5180, -6.8421, -7.3431, -5.5034], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "Epoch 11 Validation Loss: 1.014668\n",
      "[Epoch 12, Batch 100] Loss: 1.024134\n",
      "Sample outputs: tensor([ 2.0288, -3.5118, -0.7212,  0.9802, -0.5438], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 12, Batch 200] Loss: 0.970679\n",
      "Sample outputs: tensor([-2.7651,  2.4978, -3.5214, -3.5502, -3.5717], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "Epoch 12 Validation Loss: 0.973037\n",
      "[Epoch 13, Batch 100] Loss: 0.914137\n",
      "Sample outputs: tensor([ 1.6397, -2.4197, -1.2284,  1.7662,  0.8138], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 13, Batch 200] Loss: 0.934545\n",
      "Sample outputs: tensor([ 1.2661, -0.4393, -2.1948, -1.2867, -2.0795], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "Epoch 13 Validation Loss: 0.875487\n",
      "[Epoch 14, Batch 100] Loss: 0.861037\n",
      "Sample outputs: tensor([-0.1513, -2.9864,  1.6263, -0.2336,  1.8415], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 14, Batch 200] Loss: 0.915629\n",
      "Sample outputs: tensor([ 0.5419, -4.8391,  0.0727,  3.7237,  3.8269], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "Epoch 14 Validation Loss: 0.967746\n",
      "[Epoch 15, Batch 100] Loss: 0.843775\n",
      "Sample outputs: tensor([ 1.6746, -5.5686, -0.2551,  3.2113,  1.5596], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 15, Batch 200] Loss: 0.841913\n",
      "Sample outputs: tensor([-4.4657,  1.9112, -3.6848, -5.9143, -2.6697], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "Epoch 15 Validation Loss: 0.878299\n",
      "[Epoch 16, Batch 100] Loss: 0.813817\n",
      "Sample outputs: tensor([-1.8639,  1.4267, -4.0869, -3.2984, -3.2821], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 16, Batch 200] Loss: 0.809336\n",
      "Sample outputs: tensor([ 2.4418, -5.7556, -1.2267,  3.2244,  1.4515], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "Epoch 16 Validation Loss: 0.815880\n",
      "[Epoch 17, Batch 100] Loss: 0.776209\n",
      "Sample outputs: tensor([ 2.1956, -2.0587,  0.2171, -2.5299, -1.9981], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 17, Batch 200] Loss: 0.795419\n",
      "Sample outputs: tensor([-4.6992,  2.1696, -4.0150, -5.6746, -3.9906], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "Epoch 17 Validation Loss: 0.879603\n",
      "[Epoch 18, Batch 100] Loss: 0.729631\n",
      "Sample outputs: tensor([-3.4300, -3.1103,  7.1942, -3.9676, -2.5258], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 18, Batch 200] Loss: 0.751545\n",
      "Sample outputs: tensor([-1.5280, -5.1585,  4.7045,  0.4103,  2.4530], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "Epoch 18 Validation Loss: 0.886642\n",
      "[Epoch 19, Batch 100] Loss: 0.696391\n",
      "Sample outputs: tensor([ 2.5203, -6.2164,  0.2684, -0.8717,  2.5977], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 19, Batch 200] Loss: 0.748179\n",
      "Sample outputs: tensor([-0.0456, -1.9158, -1.3917,  0.3358,  1.5921], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "Epoch 19 Validation Loss: 0.811171\n",
      "[Epoch 20, Batch 100] Loss: 0.702284\n",
      "Sample outputs: tensor([ 3.8487, -8.8785, -1.7255,  1.7007,  2.3015], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 20, Batch 200] Loss: 0.703533\n",
      "Sample outputs: tensor([ 1.5431, -4.8581, -0.6912,  1.0201,  1.2726], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "Epoch 20 Validation Loss: 0.765613\n",
      "[Epoch 21, Batch 100] Loss: 0.639770\n",
      "Sample outputs: tensor([-0.6558, -3.2634, -1.6667,  0.1760,  1.5345], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 21, Batch 200] Loss: 0.673349\n",
      "Sample outputs: tensor([ 3.2438, -3.6283, -4.6763,  1.5406, -5.1906], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "Epoch 21 Validation Loss: 0.754570\n",
      "[Epoch 22, Batch 100] Loss: 0.602193\n",
      "Sample outputs: tensor([ -8.7523,   4.6341,  -2.6580, -15.3665,  -5.6886], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 22, Batch 200] Loss: 0.621370\n",
      "Sample outputs: tensor([ 5.2872, -8.0192, -1.9245,  1.0182, -0.0444], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "Epoch 22 Validation Loss: 0.801508\n",
      "[Epoch 23, Batch 100] Loss: 0.603055\n",
      "Sample outputs: tensor([ 1.2964, -6.2099, -0.4415,  3.4947,  0.1990], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 23, Batch 200] Loss: 0.600069\n",
      "Sample outputs: tensor([ 2.5036, -4.6038, -1.2194,  2.3460,  0.1999], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "Epoch 23 Validation Loss: 0.750876\n",
      "[Epoch 24, Batch 100] Loss: 0.512966\n",
      "Sample outputs: tensor([ 6.0499, -8.5062, -3.6508, -0.8300, -0.1932], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 24, Batch 200] Loss: 0.531787\n",
      "Sample outputs: tensor([-5.9076,  4.0032, -7.6405, -6.2766, -6.5289], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "Epoch 24 Validation Loss: 0.699068\n",
      "[Epoch 25, Batch 100] Loss: 0.463851\n",
      "Sample outputs: tensor([-14.8425,   5.1980,  -8.7252, -18.1852, -11.3690], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 25, Batch 200] Loss: 0.478289\n",
      "Sample outputs: tensor([-3.1171,  1.3964, -4.1248, -4.0005, -2.6851], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "Epoch 25 Validation Loss: 0.676918\n",
      "[Epoch 26, Batch 100] Loss: 0.404811\n",
      "Sample outputs: tensor([ -3.0230, -12.0009,   0.2248,   3.8439,   4.9827], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 26, Batch 200] Loss: 0.439305\n",
      "Sample outputs: tensor([-3.9565, -2.1358, -0.8254,  0.4787,  0.1722], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "Epoch 26 Validation Loss: 0.691582\n",
      "[Epoch 27, Batch 100] Loss: 0.385595\n",
      "Sample outputs: tensor([ 2.7316, -3.6766,  0.5111, -2.2685, -1.3038], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 27, Batch 200] Loss: 0.384406\n",
      "Sample outputs: tensor([ 2.6889, -5.7693,  1.0964,  0.1165, -2.2692], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "Epoch 27 Validation Loss: 0.688397\n",
      "[Epoch 28, Batch 100] Loss: 0.324493\n",
      "Sample outputs: tensor([-2.8335, -6.3289,  0.5006, -0.8056,  2.2055], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 28, Batch 200] Loss: 0.344562\n",
      "Sample outputs: tensor([ 0.2260,  0.3223,  3.9328, -2.7815, -2.6780], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "Epoch 28 Validation Loss: 0.752263\n",
      "[Epoch 29, Batch 100] Loss: 0.311614\n",
      "Sample outputs: tensor([ 7.6882, -6.9013, -3.8434, -0.1258, -4.9661], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 29, Batch 200] Loss: 0.322630\n",
      "Sample outputs: tensor([-10.8587,   4.5712,  -8.6310, -13.0071, -12.8864], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "Epoch 29 Validation Loss: 0.678489\n",
      "[Epoch 30, Batch 100] Loss: 0.255362\n",
      "Sample outputs: tensor([-9.1420,  4.4494, -7.9648, -8.4407, -5.3244], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 30, Batch 200] Loss: 0.313236\n",
      "Sample outputs: tensor([ 0.0925, -3.6189,  0.9265,  0.9687, -1.0232], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "Epoch 30 Validation Loss: 0.661315\n",
      "[Epoch 31, Batch 100] Loss: 0.237200\n",
      "Sample outputs: tensor([-6.6815,  1.5331, -2.5505, -6.6830, -1.8220], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 31, Batch 200] Loss: 0.279159\n",
      "Sample outputs: tensor([-4.0054,  1.7633, -7.1212, -4.9440, -4.2306], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "Epoch 31 Validation Loss: 0.767411\n",
      "[Epoch 32, Batch 100] Loss: 0.274241\n",
      "Sample outputs: tensor([-7.0154,  2.6426, -3.5611, -7.6380, -4.8753], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 32, Batch 200] Loss: 0.258123\n",
      "Sample outputs: tensor([-2.8005, -6.1452, -0.1256,  1.1959,  3.9601], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "Epoch 32 Validation Loss: 0.710696\n",
      "[Epoch 33, Batch 100] Loss: 0.225946\n",
      "Sample outputs: tensor([-1.5970, -9.2749,  0.0942, -3.3822,  3.1956], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 33, Batch 200] Loss: 0.197512\n",
      "Sample outputs: tensor([-5.3852, -3.5674, -3.7952, -3.5007, -6.1542], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "Epoch 33 Validation Loss: 0.735162\n",
      "[Epoch 34, Batch 100] Loss: 0.213425\n",
      "Sample outputs: tensor([ -9.7746,   3.2697,  -8.5454, -11.6805,  -5.8920], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 34, Batch 200] Loss: 0.205535\n",
      "Sample outputs: tensor([-13.4083,   5.6214,  -6.2982,  -7.3935,  -3.0466], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "Epoch 34 Validation Loss: 0.769567\n",
      "[Epoch 35, Batch 100] Loss: 0.143437\n",
      "Sample outputs: tensor([ 5.9952, -6.2383, -6.5613, -4.2653, -0.7960], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 35, Batch 200] Loss: 0.165513\n",
      "Sample outputs: tensor([-1.8608, -6.2078, -2.8379,  3.4008, -5.7377], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "Epoch 35 Validation Loss: 0.803145\n",
      "[Epoch 36, Batch 100] Loss: 0.145703\n",
      "Sample outputs: tensor([ -3.4354, -13.3023,   2.2057,  -1.5618,   3.8795], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 36, Batch 200] Loss: 0.169048\n",
      "Sample outputs: tensor([-7.2442,  3.5284, -7.0849, -8.6514, -4.5299], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "Epoch 36 Validation Loss: 0.819568\n",
      "[Epoch 37, Batch 100] Loss: 0.162047\n",
      "Sample outputs: tensor([-2.8411, -3.1202, -2.1297, -3.4106,  4.0545], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 37, Batch 200] Loss: 0.133523\n",
      "Sample outputs: tensor([-16.3665,   4.2230, -16.0079, -13.3082,  -8.9256], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "Epoch 37 Validation Loss: 0.865278\n",
      "[Epoch 38, Batch 100] Loss: 0.110725\n",
      "Sample outputs: tensor([-14.8225,  -4.8868,   1.9407,  -8.4765,  -2.3702], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 38, Batch 200] Loss: 0.114635\n",
      "Sample outputs: tensor([ 7.3960, -6.5249, -6.4251, -8.0903, -3.8699], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "Epoch 38 Validation Loss: 0.822066\n",
      "[Epoch 39, Batch 100] Loss: 0.148086\n",
      "Sample outputs: tensor([  1.6007, -16.4832,  -6.7939,   6.5950,   4.8057], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 39, Batch 200] Loss: 0.112457\n",
      "Sample outputs: tensor([  6.0306, -20.8679,  -7.4833,  -3.3411,   3.2939], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "Epoch 39 Validation Loss: 0.870504\n",
      "[Epoch 40, Batch 100] Loss: 0.111875\n",
      "Sample outputs: tensor([-2.8681, -3.4817, -0.4909, -1.8165, -1.8135], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 40, Batch 200] Loss: 0.134285\n",
      "Sample outputs: tensor([-10.4838,  -6.6550,  -0.9829,  -5.8128,  -2.0351], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "Epoch 40 Validation Loss: 0.896624\n",
      "[Epoch 41, Batch 100] Loss: 0.128766\n",
      "Sample outputs: tensor([-16.5101,   4.8730, -14.5316, -13.1172,  -4.9660], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 41, Batch 200] Loss: 0.126602\n",
      "Sample outputs: tensor([-7.2508,  4.6565, -8.6864, -7.1565, -4.7726], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "Epoch 41 Validation Loss: 0.829777\n",
      "[Epoch 42, Batch 100] Loss: 0.109494\n",
      "Sample outputs: tensor([-2.2927, -0.5427, -4.3325, -0.6711,  0.6244], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 42, Batch 200] Loss: 0.149424\n",
      "Sample outputs: tensor([-8.9179,  0.1236, -4.5754, -5.4538, -3.4869], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "Epoch 42 Validation Loss: 0.891689\n",
      "[Epoch 43, Batch 100] Loss: 0.094394\n",
      "Sample outputs: tensor([-1.5645, -4.7618, -1.3870, -5.6827,  0.4475], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 43, Batch 200] Loss: 0.090837\n",
      "Sample outputs: tensor([ 2.4743, -3.5903, -9.3167,  4.0830, -0.9146], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "Epoch 43 Validation Loss: 0.914052\n",
      "[Epoch 44, Batch 100] Loss: 0.080381\n",
      "Sample outputs: tensor([-10.5253,   2.8914,  -8.4485, -12.1408,  -8.3964], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 44, Batch 200] Loss: 0.094006\n",
      "Sample outputs: tensor([  1.4490, -12.6955, -17.8901,   1.4886,   2.1871], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "Epoch 44 Validation Loss: 1.001418\n",
      "[Epoch 45, Batch 100] Loss: 0.112000\n",
      "Sample outputs: tensor([ -9.3487,   7.4568, -10.9529,  -8.9504,  -6.3999], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 45, Batch 200] Loss: 0.079428\n",
      "Sample outputs: tensor([-17.3667,   1.3402,  -3.8261,  -9.6084,  -1.8264], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "Epoch 45 Validation Loss: 0.877359\n",
      "[Epoch 46, Batch 100] Loss: 0.079474\n",
      "Sample outputs: tensor([ 13.4806,  -3.1392,  -4.9638,  -9.1763, -16.4188], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 46, Batch 200] Loss: 0.089884\n",
      "Sample outputs: tensor([-8.4933, -1.0331, -0.6092, -5.1937, -2.8044], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "Epoch 46 Validation Loss: 0.867693\n",
      "[Epoch 47, Batch 100] Loss: 0.077707\n",
      "Sample outputs: tensor([ 0.7156, -3.4598, -3.4591,  5.5123,  0.4506], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 47, Batch 200] Loss: 0.101382\n",
      "Sample outputs: tensor([-2.8226, -1.0299, -3.2915, -6.5748, -2.2339], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "Epoch 47 Validation Loss: 0.863468\n",
      "[Epoch 48, Batch 100] Loss: 0.136448\n",
      "Sample outputs: tensor([-6.9679, -6.4673, -0.5888, -8.3059,  4.3786], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 48, Batch 200] Loss: 0.103546\n",
      "Sample outputs: tensor([-12.1934,   1.9388, -10.4504, -11.4204,  -7.6577], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "Epoch 48 Validation Loss: 0.927443\n",
      "[Epoch 49, Batch 100] Loss: 0.095455\n",
      "Sample outputs: tensor([-3.8357,  3.8701, -5.5401, -8.5724, -8.0227], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 49, Batch 200] Loss: 0.084608\n",
      "Sample outputs: tensor([  0.6682, -10.2549,   1.0781,  -7.2058,  -4.9802], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "Epoch 49 Validation Loss: 0.755933\n",
      "[Epoch 50, Batch 100] Loss: 0.050930\n",
      "Sample outputs: tensor([-22.1916,  -0.6381, -10.4684, -18.3989,  -4.7008], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 50, Batch 200] Loss: 0.054941\n",
      "Sample outputs: tensor([  2.2746, -10.6842,  -6.9828,   5.8151,   4.8327], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "Epoch 50 Validation Loss: 0.878654\n",
      "[Epoch 51, Batch 100] Loss: 0.060692\n",
      "Sample outputs: tensor([-2.7127, -4.1899, -0.9486,  2.3742,  1.7612], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 51, Batch 200] Loss: 0.071471\n",
      "Sample outputs: tensor([-5.5355,  1.2249, -4.2834, -1.1816, -0.3609], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "Epoch 51 Validation Loss: 0.854057\n",
      "[Epoch 52, Batch 100] Loss: 0.090865\n",
      "Sample outputs: tensor([ -7.6140,   5.2583, -12.1734,  -8.8767,  -6.8613], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 52, Batch 200] Loss: 0.078517\n",
      "Sample outputs: tensor([  7.6240,  -1.5175,  -5.6462,  -6.4525, -14.4049], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "Epoch 52 Validation Loss: 0.984319\n",
      "[Epoch 53, Batch 100] Loss: 0.111474\n",
      "Sample outputs: tensor([-3.3463, -7.7143, -9.8777,  1.0107,  6.1397], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 53, Batch 200] Loss: 0.083459\n",
      "Sample outputs: tensor([ -1.7131, -12.9387, -12.2833,   8.9627,  -0.3626], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "Epoch 53 Validation Loss: 0.886345\n",
      "[Epoch 54, Batch 100] Loss: 0.058969\n",
      "Sample outputs: tensor([-12.1547,   3.2535,  -6.7332,  -5.6092,   0.9374], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 54, Batch 200] Loss: 0.056045\n",
      "Sample outputs: tensor([-2.8661, -5.2937, -4.8156, -5.5787,  2.1233], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "Epoch 54 Validation Loss: 0.909874\n",
      "[Epoch 55, Batch 100] Loss: 0.058579\n",
      "Sample outputs: tensor([-3.0058e+00, -5.4988e+00,  3.0049e-03,  3.5634e+00, -4.4418e+00],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 55, Batch 200] Loss: 0.066088\n",
      "Sample outputs: tensor([  6.0571, -10.8150,  -6.0197,  -3.8132,  -5.9384], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "Epoch 55 Validation Loss: 0.933006\n",
      "[Epoch 56, Batch 100] Loss: 0.068892\n",
      "Sample outputs: tensor([-5.8379, -9.6971, -4.5281, -1.0837,  7.6306], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 56, Batch 200] Loss: 0.090898\n",
      "Sample outputs: tensor([-3.6649, -6.8578,  3.0348,  3.4813, -3.8221], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "Epoch 56 Validation Loss: 0.869348\n",
      "[Epoch 57, Batch 100] Loss: 0.088791\n",
      "Sample outputs: tensor([ 6.5569, -2.2494, -6.6046, -2.8641, -1.5507], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 57, Batch 200] Loss: 0.060091\n",
      "Sample outputs: tensor([-8.6773, -3.4600, -7.9884,  1.5556,  5.4845], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "Epoch 57 Validation Loss: 0.933350\n",
      "[Epoch 58, Batch 100] Loss: 0.078447\n",
      "Sample outputs: tensor([  7.7660,  -1.4910, -10.6974, -13.0487,  -9.4708], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 58, Batch 200] Loss: 0.080828\n",
      "Sample outputs: tensor([ 1.5726, -5.7678, -9.1719, -1.8009, -2.2196], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "Epoch 58 Validation Loss: 0.870555\n",
      "[Epoch 59, Batch 100] Loss: 0.049324\n",
      "Sample outputs: tensor([-16.3961, -21.7713,   0.9450,  -4.6699,  11.5581], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 59, Batch 200] Loss: 0.052217\n",
      "Sample outputs: tensor([ -1.2474, -17.6537,  -4.3022,   7.4595,   0.7690], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "Epoch 59 Validation Loss: 0.914713\n",
      "[Epoch 60, Batch 100] Loss: 0.052270\n",
      "Sample outputs: tensor([-3.2303,  3.7504, -7.2755, -3.3866, -4.3341], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 60, Batch 200] Loss: 0.070438\n",
      "Sample outputs: tensor([-10.9680, -13.2142,   0.7799,  -1.5812,   4.8743], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "Epoch 60 Validation Loss: 0.952107\n",
      "Finished Training\n",
      "Model saved to --HistoryManager.hist_file=:memory:\n",
      "Accuracy on the test set: 68.42%\n"
     ]
    }
   ],
   "source": [
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model instance\n",
    "model = birdClassifier().to(device)\n",
    "print(\"Model created and moved to device\")\n",
    "# Set up loss function and optimizer\n",
    "criterion = FocalLoss(alpha=1, gamma=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model with early stopping\n",
    "model = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=60,\n",
    "    patience=5,\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), modelPath)\n",
    "print(f\"Model saved to {modelPath}\")\n",
    "# hello world\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5837237,
     "sourceId": 9575326,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5928001,
     "sourceId": 9695725,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4781.005321,
   "end_time": "2024-10-23T09:37:01.482646",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-23T08:17:20.477325",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
