{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308c748c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-23T07:08:45.785417Z",
     "iopub.status.busy": "2024-10-23T07:08:45.785011Z",
     "iopub.status.idle": "2024-10-23T07:08:47.848924Z",
     "shell.execute_reply": "2024-10-23T07:08:47.847657Z"
    },
    "papermill": {
     "duration": 2.071789,
     "end_time": "2024-10-23T07:08:47.851481",
     "exception": false,
     "start_time": "2024-10-23T07:08:45.779692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp /kaggle/input/setupfiles/environment.yml /kaggle/working/\n",
    "!cp /kaggle/input/setupfiles/install.sh /kaggle/working/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59e994",
   "metadata": {
    "papermill": {
     "duration": 0.003336,
     "end_time": "2024-10-23T07:08:47.858786",
     "exception": false,
     "start_time": "2024-10-23T07:08:47.855450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dependency Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7d6e1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T07:08:47.867325Z",
     "iopub.status.busy": "2024-10-23T07:08:47.866975Z",
     "iopub.status.idle": "2024-10-23T07:09:00.942238Z",
     "shell.execute_reply": "2024-10-23T07:09:00.941358Z"
    },
    "papermill": {
     "duration": 13.082084,
     "end_time": "2024-10-23T07:09:00.944446",
     "exception": false,
     "start_time": "2024-10-23T07:08:47.862362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies from environment.yml using pip...\r\n",
      "Environment setup completed successfully!\r\n"
     ]
    }
   ],
   "source": [
    "!bash install.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d75c1c",
   "metadata": {
    "papermill": {
     "duration": 0.003454,
     "end_time": "2024-10-23T07:09:00.951969",
     "exception": false,
     "start_time": "2024-10-23T07:09:00.948515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0197fad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T07:09:00.960837Z",
     "iopub.status.busy": "2024-10-23T07:09:00.960519Z",
     "iopub.status.idle": "2024-10-23T07:09:07.251491Z",
     "shell.execute_reply": "2024-10-23T07:09:07.250629Z"
    },
    "papermill": {
     "duration": 6.298477,
     "end_time": "2024-10-23T07:09:07.253973",
     "exception": false,
     "start_time": "2024-10-23T07:09:00.955496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65a435d",
   "metadata": {
    "papermill": {
     "duration": 0.003783,
     "end_time": "2024-10-23T07:09:07.262186",
     "exception": false,
     "start_time": "2024-10-23T07:09:07.258403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Class Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "696f8127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T07:09:07.272581Z",
     "iopub.status.busy": "2024-10-23T07:09:07.272111Z",
     "iopub.status.idle": "2024-10-23T07:09:07.304625Z",
     "shell.execute_reply": "2024-10-23T07:09:07.303874Z"
    },
    "papermill": {
     "duration": 0.040702,
     "end_time": "2024-10-23T07:09:07.306557",
     "exception": false,
     "start_time": "2024-10-23T07:09:07.265855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class birdClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(birdClassifier, self).__init__()\n",
    "        print(\"Initializing birdClassifier\")\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  # Conv1: 64 filters\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),  # Conv2: 64 filters\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Pooling reduces size by half\n",
    "            # Block 2\n",
    "            nn.Conv2d(\n",
    "                64, 128, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv3: 128 filters\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                128, 128, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv4: 128 filters\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Block 3\n",
    "            nn.Conv2d(\n",
    "                128, 256, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv5: 256 filters\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                256, 256, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv6: 256 filters\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                256, 256, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv7: 256 filters\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Block 4\n",
    "            nn.Conv2d(\n",
    "                256, 512, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv8: 512 filters\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                512, 512, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv9: 512 filters\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                512, 512, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv10: 512 filters\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Block 5\n",
    "            nn.Conv2d(\n",
    "                512, 1024, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv11: 1024 filters\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                1024, 1024, kernel_size=3, stride=1, padding=1\n",
    "            ),  # Conv12: 1024 filters\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024 * 7 * 7, 4096),  # Fully connected layer 1\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Dropout for regularization\n",
    "            nn.Linear(4096, 4096),  # Fully connected layer 2\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 10))  # Output layer (10 bird classes))\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction=\"none\")\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=60,\n",
    "    patience=10,\n",
    "):\n",
    "    print(\"Starting model training\")\n",
    "    model.train()\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_without_improvement = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % 100 == 99:  # Print every 100 mini-batches\n",
    "                print(\n",
    "                    f\"[Epoch {epoch + 1}, Batch {i + 1}] Loss: {running_loss / 100:.6f}\"\n",
    "                )\n",
    "                print(f\"Sample outputs: {outputs[0][:5]}\")\n",
    "                print(f\"Sample labels: {labels[0]}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Epoch {epoch + 1} Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "\n",
    "    print(\"Finished Training\")\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab38641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T07:09:07.315792Z",
     "iopub.status.busy": "2024-10-23T07:09:07.315480Z",
     "iopub.status.idle": "2024-10-23T07:10:14.757769Z",
     "shell.execute_reply": "2024-10-23T07:10:14.756394Z"
    },
    "papermill": {
     "duration": 67.449389,
     "end_time": "2024-10-23T07:10:14.760013",
     "exception": false,
     "start_time": "2024-10-23T07:09:07.310624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script started\n",
      "Data path: /kaggle/input/identify-the-birds/Birds/train\n",
      "Train status: train\n",
      "Model path: --HistoryManager.hist_file=:memory:\n",
      "Entering training mode\n",
      "Label distribution: {0: 686, 6: 764, 5: 779, 7: 613, 3: 522, 8: 607, 2: 461, 9: 549, 1: 622, 4: 771}\n",
      "Input data range: [0.00, 1.00]\n"
     ]
    }
   ],
   "source": [
    "print(\"Script started\")\n",
    "dataPath = \"/kaggle/input/identify-the-birds/Birds/train\"\n",
    "trainStatus = \"train\"\n",
    "modelPath = sys.argv[3] if len(sys.argv) > 3 else \"model.pth\"\n",
    "\n",
    "print(f\"Data path: {dataPath}\")\n",
    "print(f\"Train status: {trainStatus}\")\n",
    "print(f\"Model path: {modelPath}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Entering training mode\")\n",
    "\n",
    "# Set up data transformations\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "full_dataset = datasets.ImageFolder(root=dataPath, transform=transform)\n",
    "\n",
    "# Create train-test split\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(full_dataset)),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=full_dataset.targets,\n",
    ")\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "label_counts = {}\n",
    "for _, labels in train_loader:\n",
    "    for label in labels:\n",
    "        label_counts[label.item()] = label_counts.get(label.item(), 0) + 1\n",
    "print(\"Label distribution:\", label_counts)\n",
    "\n",
    "\n",
    "# Check input data range\n",
    "for inputs, labels in train_loader:\n",
    "    print(f\"Input data range: [{inputs.min().item():.2f}, {inputs.max().item():.2f}]\")\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d87e015",
   "metadata": {
    "papermill": {
     "duration": 0.003651,
     "end_time": "2024-10-23T07:10:14.768027",
     "exception": false,
     "start_time": "2024-10-23T07:10:14.764376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Run your .py file on CLI using the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b584df10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-23T07:10:14.778117Z",
     "iopub.status.busy": "2024-10-23T07:10:14.777405Z",
     "iopub.status.idle": "2024-10-23T07:54:26.361529Z",
     "shell.execute_reply": "2024-10-23T07:54:26.359973Z"
    },
    "papermill": {
     "duration": 2651.59179,
     "end_time": "2024-10-23T07:54:26.364015",
     "exception": false,
     "start_time": "2024-10-23T07:10:14.772225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing birdClassifier\n",
      "Model created and moved to device\n",
      "Starting model training\n",
      "[Epoch 1, Batch 100] Loss: 78.928269\n",
      "Sample outputs: tensor([  27.1459, -110.0038,   19.0432,  -34.3762,  -26.9180],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 1, Batch 200] Loss: 31.271787\n",
      "Sample outputs: tensor([ 0.2072,  1.7453, -2.6475,  2.0727,  0.1883], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 1, Batch 300] Loss: 4.887303\n",
      "Sample outputs: tensor([ 0.0947,  0.2200, -0.6151, -0.3918,  0.4836], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 1, Batch 400] Loss: 1.889416\n",
      "Sample outputs: tensor([ 0.2301, -0.0640, -0.5489, -0.1720,  0.3677], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 1, Batch 500] Loss: 1.891694\n",
      "Sample outputs: tensor([-0.1423,  0.5796, -0.3169, -0.4056,  0.2484], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 1, Batch 600] Loss: 1.868741\n",
      "Sample outputs: tensor([ 0.3414, -0.0973, -0.9085, -0.2415,  0.3420], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 1, Batch 700] Loss: 1.876149\n",
      "Sample outputs: tensor([ 0.0407, -0.1511, -0.0160, -0.0068,  0.5369], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 1, Batch 800] Loss: 1.903804\n",
      "Sample outputs: tensor([ 0.7078, -0.1936, -0.1159, -0.7128,  0.2237], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 1, Batch 900] Loss: 1.895545\n",
      "Sample outputs: tensor([ 0.4128, -0.6211, -0.4642, -0.2765,  0.1645], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 1, Batch 1000] Loss: 1.929868\n",
      "Sample outputs: tensor([ 0.2185, -0.1587, -0.2062, -0.4636,  0.6396], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 1, Batch 1100] Loss: 1.881746\n",
      "Sample outputs: tensor([ 0.4523,  0.5859, -0.6296, -0.5768,  0.1763], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 1, Batch 1200] Loss: 1.938079\n",
      "Sample outputs: tensor([ 0.1360,  0.0090,  0.1823, -0.0613, -0.0211], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 1, Batch 1300] Loss: 1.907998\n",
      "Sample outputs: tensor([-0.3570, -0.4284,  0.2867,  0.0447,  0.2097], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 1, Batch 1400] Loss: 1.861856\n",
      "Sample outputs: tensor([ 0.4947, -0.4029, -0.1845, -0.2101,  0.4048], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 1, Batch 1500] Loss: 1.931008\n",
      "Sample outputs: tensor([-0.3425,  0.2897,  0.2649, -0.2719,  0.4204], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 1, Batch 1600] Loss: 1.906939\n",
      "Sample outputs: tensor([-0.4022, -0.0750, -0.3161,  0.2386,  0.1771], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 1, Batch 1700] Loss: 1.886902\n",
      "Sample outputs: tensor([ 0.2321,  0.2167, -0.8558,  0.1797,  0.0578], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 1, Batch 1800] Loss: 1.916383\n",
      "Sample outputs: tensor([-0.1784,  0.0861,  0.1954, -0.1016,  0.4225], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 1, Batch 1900] Loss: 1.902198\n",
      "Sample outputs: tensor([ 0.2225, -0.1491, -0.3518,  0.3375,  0.1203], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 1, Batch 2000] Loss: 1.900510\n",
      "Sample outputs: tensor([ 0.4152,  0.2434, -0.8180, -0.1107,  0.0859], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 1, Batch 2100] Loss: 1.915440\n",
      "Sample outputs: tensor([ 0.1875, -0.3777, -0.2510, -0.4170, -0.0352], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "Epoch 1 Validation Loss: 12.841806\n",
      "[Epoch 2, Batch 100] Loss: 1.876483\n",
      "Sample outputs: tensor([ 0.0385,  0.3967, -0.5807,  0.1104,  0.0684], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 2, Batch 200] Loss: 1.902809\n",
      "Sample outputs: tensor([-0.2987,  0.2570, -0.2785,  0.1394,  0.1507], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 2, Batch 300] Loss: 1.910874\n",
      "Sample outputs: tensor([ 0.2220, -0.4443, -0.7256, -0.1142,  0.1992], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 2, Batch 400] Loss: 1.890609\n",
      "Sample outputs: tensor([-0.2135,  0.3697, -0.0829, -0.2397,  0.4615], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 2, Batch 500] Loss: 1.862009\n",
      "Sample outputs: tensor([-0.1062, -0.0179, -0.6798, -0.1366,  0.5936], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 2, Batch 600] Loss: 1.904904\n",
      "Sample outputs: tensor([ 0.4400,  0.0855, -0.3639, -0.2014,  0.0165], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 2, Batch 700] Loss: 1.935237\n",
      "Sample outputs: tensor([ 0.0484, -0.2988, -0.5216,  0.2838,  0.4064], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 2, Batch 800] Loss: 1.891698\n",
      "Sample outputs: tensor([ 0.4841, -0.2348, -0.1707, -0.5962,  0.1543], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 2, Batch 900] Loss: 1.897706\n",
      "Sample outputs: tensor([-0.0264, -0.2361, -0.3113,  0.0455,  0.3392], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 2, Batch 1000] Loss: 1.916204\n",
      "Sample outputs: tensor([ 0.1481,  0.2101, -0.3416, -0.2529, -0.0236], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 2, Batch 1100] Loss: 1.901177\n",
      "Sample outputs: tensor([ 0.1585,  0.0452, -0.0825, -0.0964, -0.0097], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 2, Batch 1200] Loss: 1.875158\n",
      "Sample outputs: tensor([ 0.0229, -0.5033, -0.3754, -0.3581,  0.7613], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 2, Batch 1300] Loss: 1.901428\n",
      "Sample outputs: tensor([-0.1256,  0.2722, -0.7110, -0.2298,  0.6674], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 2, Batch 1400] Loss: 1.905155\n",
      "Sample outputs: tensor([-0.0927, -0.4083, -0.5939, -0.1829,  0.2253], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 2, Batch 1500] Loss: 1.908236\n",
      "Sample outputs: tensor([ 0.1000,  0.2601, -0.5226, -0.3524, -0.1634], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 2, Batch 1600] Loss: 1.898911\n",
      "Sample outputs: tensor([ 0.5507, -0.0221, -0.4311, -0.5653,  0.1997], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 2, Batch 1700] Loss: 1.886846\n",
      "Sample outputs: tensor([ 0.0213, -0.1052, -0.5782,  0.0338,  0.3168], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 2, Batch 1800] Loss: 1.876889\n",
      "Sample outputs: tensor([-0.0026, -0.2391, -0.2161, -0.0987,  0.1074], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 2, Batch 1900] Loss: 1.897147\n",
      "Sample outputs: tensor([-0.2998,  0.3041,  0.1952, -0.3474,  0.0855], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 2, Batch 2000] Loss: 1.912051\n",
      "Sample outputs: tensor([-0.3771, -0.2687, -0.4448,  0.4071,  0.7538], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 2, Batch 2100] Loss: 1.914075\n",
      "Sample outputs: tensor([ 0.3540,  0.3722,  0.1624, -0.6250,  0.1672], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "Epoch 2 Validation Loss: 9.800128\n",
      "[Epoch 3, Batch 100] Loss: 1.913733\n",
      "Sample outputs: tensor([ 0.2569,  0.2684, -0.1529, -0.4414,  0.2291], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 3, Batch 200] Loss: 1.917065\n",
      "Sample outputs: tensor([-0.2932,  0.2299, -0.6015, -0.3169,  0.0469], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 3, Batch 300] Loss: 1.891154\n",
      "Sample outputs: tensor([ 0.0842, -0.3301, -0.4788,  0.6601,  0.2393], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 3, Batch 400] Loss: 1.878972\n",
      "Sample outputs: tensor([ 0.1277,  0.5621, -0.5781, -0.3941,  0.4242], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 3, Batch 500] Loss: 1.929065\n",
      "Sample outputs: tensor([-0.1386, -0.1440, -0.2706,  0.0171,  0.7223], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 3, Batch 600] Loss: 1.887286\n",
      "Sample outputs: tensor([ 0.2195,  0.6226, -0.5089, -0.0366,  0.0573], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 3, Batch 700] Loss: 1.895970\n",
      "Sample outputs: tensor([ 0.0500,  0.2042, -0.3085, -0.3305,  0.1484], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 3, Batch 800] Loss: 1.894206\n",
      "Sample outputs: tensor([ 0.1876,  0.1351,  0.1647, -0.3780, -0.1128], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 3, Batch 900] Loss: 1.905130\n",
      "Sample outputs: tensor([-0.0972, -0.1548, -0.5487, -0.3348,  0.7521], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 3, Batch 1000] Loss: 1.875543\n",
      "Sample outputs: tensor([ 0.2318,  0.3179, -0.5118, -0.2487,  0.2485], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 3, Batch 1100] Loss: 1.904828\n",
      "Sample outputs: tensor([-0.2926,  0.1214, -0.1103,  0.1968,  0.1145], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 3, Batch 1200] Loss: 1.900289\n",
      "Sample outputs: tensor([ 0.1085,  0.1237, -0.4334,  0.1856,  0.1898], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 3, Batch 1300] Loss: 1.905527\n",
      "Sample outputs: tensor([ 0.1305,  0.0391, -0.2524,  0.0060,  0.5938], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 3, Batch 1400] Loss: 1.899597\n",
      "Sample outputs: tensor([ 0.2823, -0.0575, -0.1180, -0.6264,  0.4303], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 3, Batch 1500] Loss: 1.935327\n",
      "Sample outputs: tensor([ 0.2183, -0.0890,  0.0580, -0.3337,  0.2963], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 3, Batch 1600] Loss: 1.900072\n",
      "Sample outputs: tensor([ 0.3546, -0.4536, -0.4222, -0.3363,  0.8310], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 3, Batch 1700] Loss: 1.890223\n",
      "Sample outputs: tensor([-0.0602, -0.0331, -0.5411, -0.0020,  0.0815], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 3, Batch 1800] Loss: 1.900952\n",
      "Sample outputs: tensor([-0.4065,  0.1585,  0.0124, -0.7735,  0.4174], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 3, Batch 1900] Loss: 1.905343\n",
      "Sample outputs: tensor([ 0.0250, -0.0971,  0.0496,  0.0792,  0.2055], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 3, Batch 2000] Loss: 1.913020\n",
      "Sample outputs: tensor([ 0.1127, -0.0905, -0.3535, -0.0911, -0.0423], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 3, Batch 2100] Loss: 1.886486\n",
      "Sample outputs: tensor([ 0.2995,  0.0960, -0.1807, -0.3888,  0.2390], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "Epoch 3 Validation Loss: 6.522719\n",
      "[Epoch 4, Batch 100] Loss: 1.907069\n",
      "Sample outputs: tensor([ 0.4360,  0.0868, -0.2078, -0.1702,  0.0184], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 4, Batch 200] Loss: 1.866005\n",
      "Sample outputs: tensor([-0.1035,  0.1953, -0.2024, -0.9078,  0.9356], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 4, Batch 300] Loss: 1.908336\n",
      "Sample outputs: tensor([ 0.1577, -0.4339, -0.1837,  0.1053, -0.0922], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 4, Batch 400] Loss: 1.912619\n",
      "Sample outputs: tensor([ 0.0640, -0.1883, -0.3013,  0.3341,  0.3357], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 4, Batch 500] Loss: 1.876742\n",
      "Sample outputs: tensor([ 0.2818,  0.1770, -0.5717, -0.4748,  0.4616], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 4, Batch 600] Loss: 1.921840\n",
      "Sample outputs: tensor([-0.2010, -0.4739, -0.4029,  0.4819,  0.3972], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 4, Batch 700] Loss: 1.924395\n",
      "Sample outputs: tensor([-0.2251,  0.0234, -0.0465, -0.1967,  0.0673], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 4, Batch 800] Loss: 1.881677\n",
      "Sample outputs: tensor([ 0.7408, -0.4188, -0.6447, -0.2700,  0.1779], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 4, Batch 900] Loss: 1.909538\n",
      "Sample outputs: tensor([ 0.2585,  0.0207, -0.6756, -0.1731,  0.3289], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 4, Batch 1000] Loss: 1.895726\n",
      "Sample outputs: tensor([ 0.3855,  0.5288, -0.1009,  0.0899,  0.0175], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 4, Batch 1100] Loss: 1.895612\n",
      "Sample outputs: tensor([ 0.3480, -0.1903, -0.4927, -0.5322,  0.2509], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 4, Batch 1200] Loss: 1.900408\n",
      "Sample outputs: tensor([-0.2471, -0.3171, -0.1952, -0.1987,  0.6134], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 4, Batch 1300] Loss: 1.910778\n",
      "Sample outputs: tensor([-0.1026,  0.2170, -0.2167, -0.3250, -0.0178], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 4, Batch 1400] Loss: 1.897358\n",
      "Sample outputs: tensor([ 0.3417, -0.2408, -0.3846, -0.5473,  0.7163], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 4, Batch 1500] Loss: 1.901635\n",
      "Sample outputs: tensor([ 0.6030, -0.4373, -0.3900, -0.1182,  0.0299], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 4, Batch 1600] Loss: 1.888757\n",
      "Sample outputs: tensor([ 0.0285,  0.1274, -0.0950,  0.5340,  0.2006], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 4, Batch 1700] Loss: 1.910972\n",
      "Sample outputs: tensor([-0.2142,  0.0831, -0.3111, -0.1878, -0.0753], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 4, Batch 1800] Loss: 1.882294\n",
      "Sample outputs: tensor([ 0.1001, -0.4611, -0.4103,  0.1550,  0.3457], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 4, Batch 1900] Loss: 1.910052\n",
      "Sample outputs: tensor([-0.2750, -0.1658, -0.4837,  0.0961,  0.5035], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 4, Batch 2000] Loss: 1.915762\n",
      "Sample outputs: tensor([ 0.1450, -0.0679, -0.2947, -0.1314,  0.4731], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 4, Batch 2100] Loss: 1.887080\n",
      "Sample outputs: tensor([-0.2529,  0.3680,  0.0082, -0.2505,  0.3310], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "Epoch 4 Validation Loss: 16.217755\n",
      "[Epoch 5, Batch 100] Loss: 1.905424\n",
      "Sample outputs: tensor([ 0.0324,  0.2509, -0.3504, -0.5144,  0.3126], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 5, Batch 200] Loss: 1.920325\n",
      "Sample outputs: tensor([-0.1055, -0.3813, -0.4946, -0.1543,  0.6165], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 5, Batch 300] Loss: 1.925906\n",
      "Sample outputs: tensor([-0.2537,  0.5479, -0.9158, -0.0906, -0.0061], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 5, Batch 400] Loss: 1.891195\n",
      "Sample outputs: tensor([-0.4285,  0.3301, -0.2188, -0.2728,  0.3078], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 5, Batch 500] Loss: 1.861374\n",
      "Sample outputs: tensor([ 0.2447, -0.5576, -0.4948, -0.3434,  0.2356], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 5, Batch 600] Loss: 1.885239\n",
      "Sample outputs: tensor([ 0.3491, -0.4308, -0.1693, -0.7305,  0.2025], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 5, Batch 700] Loss: 1.928494\n",
      "Sample outputs: tensor([-0.0172,  0.4275,  0.0795, -0.3303,  0.2539], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 5, Batch 800] Loss: 1.876010\n",
      "Sample outputs: tensor([ 0.2095,  0.1816, -0.7790, -0.1359, -0.1881], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 5, Batch 900] Loss: 1.871735\n",
      "Sample outputs: tensor([ 0.0755, -0.5768, -0.9562, -0.1129,  0.1866], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 5, Batch 1000] Loss: 1.907948\n",
      "Sample outputs: tensor([ 0.1583,  0.4374, -0.2159,  0.0214,  0.0449], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 5, Batch 1100] Loss: 1.904552\n",
      "Sample outputs: tensor([-0.1273,  0.1207, -0.0572, -0.1290,  0.7777], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 5, Batch 1200] Loss: 1.866016\n",
      "Sample outputs: tensor([ 0.1142,  0.0413, -0.6482, -0.3684,  0.3933], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 5, Batch 1300] Loss: 1.876261\n",
      "Sample outputs: tensor([ 0.0763, -0.3297, -0.9878, -0.2534,  0.3872], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 5, Batch 1400] Loss: 1.921845\n",
      "Sample outputs: tensor([-0.3198,  0.5668,  0.1673, -0.1170,  0.1234], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 5, Batch 1500] Loss: 1.907910\n",
      "Sample outputs: tensor([-0.1797, -0.1826, -0.0464, -0.2569,  0.4468], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 5, Batch 1600] Loss: 1.909004\n",
      "Sample outputs: tensor([-0.0428, -0.4250,  0.3909,  0.2405,  0.1401], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 5, Batch 1700] Loss: 1.922473\n",
      "Sample outputs: tensor([ 0.3262,  0.0125, -0.2949,  0.3890,  0.2511], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 5, Batch 1800] Loss: 1.916416\n",
      "Sample outputs: tensor([-0.1405,  0.3575, -0.6905, -0.0392,  0.2918], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 5, Batch 1900] Loss: 1.899345\n",
      "Sample outputs: tensor([ 0.5772,  0.1039, -0.3585,  0.0580, -0.2223], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 5, Batch 2000] Loss: 1.903948\n",
      "Sample outputs: tensor([-0.4449, -0.1576, -0.1511,  0.6703,  0.6126], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 5, Batch 2100] Loss: 1.936363\n",
      "Sample outputs: tensor([ 0.0567, -0.3120, -0.1415,  0.4254,  0.1289], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "Epoch 5 Validation Loss: 8.931919\n",
      "[Epoch 6, Batch 100] Loss: 1.873596\n",
      "Sample outputs: tensor([-0.1772,  0.4556, -0.3237, -0.1821,  0.1367], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 6, Batch 200] Loss: 1.926266\n",
      "Sample outputs: tensor([ 0.2498, -0.0502,  0.2012, -0.4091, -0.3926], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 6, Batch 300] Loss: 1.926976\n",
      "Sample outputs: tensor([ 0.3327,  0.0732, -0.3747, -0.0064,  0.3670], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 6, Batch 400] Loss: 1.911674\n",
      "Sample outputs: tensor([-0.0285, -0.1568,  0.1725, -0.0754,  0.1387], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 6, Batch 500] Loss: 1.906025\n",
      "Sample outputs: tensor([ 0.2433,  0.3706, -0.2638, -0.3999,  0.0530], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 6, Batch 600] Loss: 1.887819\n",
      "Sample outputs: tensor([-0.1908,  0.1996, -0.3356, -0.0485,  0.3329], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 6, Batch 700] Loss: 1.903510\n",
      "Sample outputs: tensor([ 0.0974,  0.0765, -0.6253,  0.3845, -0.1688], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 6, Batch 800] Loss: 1.921857\n",
      "Sample outputs: tensor([ 0.0511, -0.0354,  0.0523, -0.4557, -0.1792], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 6, Batch 900] Loss: 1.896985\n",
      "Sample outputs: tensor([ 0.0329, -0.2687, -0.5175, -0.0201,  0.0268], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 6, Batch 1000] Loss: 1.906073\n",
      "Sample outputs: tensor([ 0.3362, -0.1659, -0.2481, -0.2362,  0.2899], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 6, Batch 1100] Loss: 1.875320\n",
      "Sample outputs: tensor([ 0.0740, -0.0477, -1.1688, -0.4444,  0.1739], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 6, Batch 1200] Loss: 1.929698\n",
      "Sample outputs: tensor([-0.0014, -0.0891, -0.0737, -0.1909,  0.3968], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 6, Batch 1300] Loss: 1.904973\n",
      "Sample outputs: tensor([ 0.1409,  0.0807, -0.4674, -0.3803, -0.0746], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 6, Batch 1400] Loss: 1.910009\n",
      "Sample outputs: tensor([-0.0205,  0.1693, -0.5937, -0.3282,  0.3804], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 6, Batch 1500] Loss: 1.907075\n",
      "Sample outputs: tensor([-0.0793,  0.2041, -0.6517, -0.2690,  0.4448], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 6, Batch 1600] Loss: 1.925575\n",
      "Sample outputs: tensor([-0.1193,  0.0947, -0.6292, -0.7219,  0.4647], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 6, Batch 1700] Loss: 1.858215\n",
      "Sample outputs: tensor([ 0.2637, -0.3076, -0.7770, -0.1940,  0.0331], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 6, Batch 1800] Loss: 1.899265\n",
      "Sample outputs: tensor([ 0.5276, -0.1669, -0.1531, -0.1282,  0.6850], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 6, Batch 1900] Loss: 1.926944\n",
      "Sample outputs: tensor([-0.0583,  0.2895,  0.1738, -0.4406,  0.5056], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 6, Batch 2000] Loss: 1.917442\n",
      "Sample outputs: tensor([ 0.3396, -0.1957, -0.3879,  0.0580,  0.4302], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 6, Batch 2100] Loss: 1.908547\n",
      "Sample outputs: tensor([ 0.0347,  0.0493, -0.0603,  0.1895,  0.4038], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "Epoch 6 Validation Loss: 5.858016\n",
      "[Epoch 7, Batch 100] Loss: 1.885151\n",
      "Sample outputs: tensor([ 0.4917,  0.4173, -0.7479, -0.0975,  0.0083], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 7, Batch 200] Loss: 1.879969\n",
      "Sample outputs: tensor([ 0.4534, -0.7227, -0.6187, -0.2960,  0.7183], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 7, Batch 300] Loss: 1.912764\n",
      "Sample outputs: tensor([ 0.4311, -0.3237, -0.0378, -0.1967,  0.1324], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 7, Batch 400] Loss: 1.901115\n",
      "Sample outputs: tensor([ 0.1538, -0.0385, -0.4730, -0.3957,  0.3105], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 7, Batch 500] Loss: 1.882743\n",
      "Sample outputs: tensor([ 0.2047, -0.2232, -0.0205, -0.3556, -0.0055], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 7, Batch 600] Loss: 1.910953\n",
      "Sample outputs: tensor([ 0.4540, -0.1336, -0.4942, -0.2488,  0.1654], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 7, Batch 700] Loss: 1.865933\n",
      "Sample outputs: tensor([ 0.6276,  0.0191, -0.6232, -0.3622,  0.9494], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 7, Batch 800] Loss: 1.916817\n",
      "Sample outputs: tensor([ 0.1176,  0.4078, -0.2166,  0.1075, -0.4392], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 7, Batch 900] Loss: 1.886342\n",
      "Sample outputs: tensor([-0.1393,  0.3466, -0.7136,  0.3805,  0.3619], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 7, Batch 1000] Loss: 1.937893\n",
      "Sample outputs: tensor([-0.2233,  0.1752, -0.3758, -0.1573,  0.1943], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 7, Batch 1100] Loss: 1.870662\n",
      "Sample outputs: tensor([ 0.3359, -0.2090, -0.5903, -0.4831, -0.1003], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 7, Batch 1200] Loss: 1.928528\n",
      "Sample outputs: tensor([ 0.0150,  0.0580, -0.5235, -0.5769,  0.3022], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 7, Batch 1300] Loss: 1.904150\n",
      "Sample outputs: tensor([-0.1966,  0.1862, -0.0818,  0.1730,  0.1142], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 7, Batch 1400] Loss: 1.899115\n",
      "Sample outputs: tensor([-0.0535, -0.5068, -0.4327, -0.2631,  0.3661], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 7, Batch 1500] Loss: 1.876832\n",
      "Sample outputs: tensor([-0.2487,  0.3829, -0.5289,  0.1251,  0.0254], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 7, Batch 1600] Loss: 1.910011\n",
      "Sample outputs: tensor([-0.4641,  0.0852, -0.4213, -0.7070,  0.3034], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 7, Batch 1700] Loss: 1.915877\n",
      "Sample outputs: tensor([ 0.2738, -0.2755, -0.3075,  0.0215, -0.3837], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 7, Batch 1800] Loss: 1.914317\n",
      "Sample outputs: tensor([-0.4425,  0.1694, -0.1317, -0.2050,  0.4145], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 7, Batch 1900] Loss: 1.892372\n",
      "Sample outputs: tensor([ 0.1158, -0.1549,  0.0553, -0.2168,  0.4992], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 7, Batch 2000] Loss: 1.890370\n",
      "Sample outputs: tensor([ 0.0521, -0.3984, -0.4416, -0.2058,  0.4466], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 7, Batch 2100] Loss: 1.889017\n",
      "Sample outputs: tensor([ 0.0236, -0.2685, -0.5992, -0.5370,  0.5081], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "Epoch 7 Validation Loss: 6.419795\n",
      "[Epoch 8, Batch 100] Loss: 1.912697\n",
      "Sample outputs: tensor([-0.0032, -0.1246, -0.1367,  0.0795,  0.3511], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 8, Batch 200] Loss: 1.888686\n",
      "Sample outputs: tensor([-0.6036,  0.0808,  0.0577, -0.3988,  0.6898], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 8, Batch 300] Loss: 1.899987\n",
      "Sample outputs: tensor([ 0.3413, -0.3763, -0.2890, -0.5197,  0.2825], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 8, Batch 400] Loss: 1.907168\n",
      "Sample outputs: tensor([-0.2166,  0.1714, -0.3082,  0.2068,  0.1680], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 8, Batch 500] Loss: 1.889868\n",
      "Sample outputs: tensor([-0.1947, -0.3321, -0.3786, -0.3131,  0.3538], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 8, Batch 600] Loss: 1.882392\n",
      "Sample outputs: tensor([ 0.0282, -0.3329, -0.5527, -0.3869,  0.6306], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 8, Batch 700] Loss: 1.941067\n",
      "Sample outputs: tensor([-0.0415, -0.2519, -0.2014, -0.2425,  0.2710], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 8, Batch 800] Loss: 1.896233\n",
      "Sample outputs: tensor([ 0.0367, -0.1805, -0.5363, -0.3125,  0.5963], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 8, Batch 900] Loss: 1.912730\n",
      "Sample outputs: tensor([-0.0393, -0.1175,  0.4055, -0.4252,  0.0535], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 8, Batch 1000] Loss: 1.913568\n",
      "Sample outputs: tensor([ 0.2479,  0.2844, -0.6277, -0.4518,  0.3517], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 8, Batch 1100] Loss: 1.894540\n",
      "Sample outputs: tensor([ 0.2608, -0.2704, -0.1549, -0.0746,  0.2591], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 8, Batch 1200] Loss: 1.867229\n",
      "Sample outputs: tensor([ 0.1086, -0.4095, -0.9347, -0.5547,  0.3556], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 8, Batch 1300] Loss: 1.911589\n",
      "Sample outputs: tensor([-1.3586e-04, -1.1001e-01, -1.2112e-01,  1.2558e-01, -2.5616e-01],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 8, Batch 1400] Loss: 1.896606\n",
      "Sample outputs: tensor([ 0.0358,  0.1954, -0.3756,  0.1712, -0.1089], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 8, Batch 1500] Loss: 1.897166\n",
      "Sample outputs: tensor([ 0.4299,  0.2524, -0.9745, -0.0176, -0.0536], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 8, Batch 1600] Loss: 1.886700\n",
      "Sample outputs: tensor([0.1010, 0.1456, 0.1133, 0.4859, 0.0295], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 8, Batch 1700] Loss: 1.904600\n",
      "Sample outputs: tensor([ 0.3006, -0.1312, -0.3236, -0.0114,  0.7117], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 8, Batch 1800] Loss: 1.899339\n",
      "Sample outputs: tensor([-0.1907,  0.3569, -0.5295, -0.0325,  0.3621], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 8, Batch 1900] Loss: 1.889685\n",
      "Sample outputs: tensor([ 1.3831e-04,  3.3307e-01, -2.9139e-02, -3.6164e-01,  1.0602e+00],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 8, Batch 2000] Loss: 1.917567\n",
      "Sample outputs: tensor([ 0.0537, -0.1316, -0.3867, -0.4045,  0.6444], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 8, Batch 2100] Loss: 1.898585\n",
      "Sample outputs: tensor([-0.0311,  0.3004, -0.1877,  0.1915,  0.5636], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "Epoch 8 Validation Loss: 4.135431\n",
      "[Epoch 9, Batch 100] Loss: 1.907370\n",
      "Sample outputs: tensor([-0.2724, -0.1680, -0.0773, -0.1248,  0.3427], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 9, Batch 200] Loss: 1.924620\n",
      "Sample outputs: tensor([-0.0516,  0.2092, -0.3401,  0.0931,  0.3040], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 9, Batch 300] Loss: 1.885825\n",
      "Sample outputs: tensor([ 0.0541,  0.5137, -0.8926,  0.4338,  0.2238], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 9, Batch 400] Loss: 1.936279\n",
      "Sample outputs: tensor([ 0.1778,  0.4597, -0.3413, -0.1010,  0.0856], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 9, Batch 500] Loss: 1.877991\n",
      "Sample outputs: tensor([ 0.1613, -0.2837, -0.3437,  0.0069,  0.3292], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 9, Batch 600] Loss: 1.880001\n",
      "Sample outputs: tensor([-0.2888, -0.0169, -0.2629,  0.3767,  0.6287], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 9, Batch 700] Loss: 1.918364\n",
      "Sample outputs: tensor([ 0.5851, -0.6180, -0.0857, -0.0150, -0.1009], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 9, Batch 800] Loss: 1.862667\n",
      "Sample outputs: tensor([ 0.4313,  0.6215, -0.9412, -0.7626, -0.0458], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 9, Batch 900] Loss: 1.932081\n",
      "Sample outputs: tensor([ 0.0443,  0.1781, -0.6060, -0.4319,  0.3828], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 9, Batch 1000] Loss: 1.901420\n",
      "Sample outputs: tensor([ 0.0958, -0.2610, -0.1476, -0.7986,  0.2625], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 9, Batch 1100] Loss: 1.926046\n",
      "Sample outputs: tensor([ 0.5190, -0.2217, -0.1091, -0.5644,  0.3535], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 9, Batch 1200] Loss: 1.873100\n",
      "Sample outputs: tensor([ 0.6346,  0.2357, -1.0236, -0.2923, -0.1940], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 9, Batch 1300] Loss: 1.889360\n",
      "Sample outputs: tensor([ 0.6494, -0.2729, -0.3779, -0.6596,  0.2556], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 9, Batch 1400] Loss: 1.909961\n",
      "Sample outputs: tensor([ 0.6317, -0.2973, -0.8657, -0.1978, -0.2476], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 9, Batch 1500] Loss: 1.891981\n",
      "Sample outputs: tensor([ 0.2140, -0.6046, -0.6000, -0.3791,  0.3577], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 9, Batch 1600] Loss: 1.898538\n",
      "Sample outputs: tensor([ 0.0436,  0.0923, -0.5720, -0.2993,  0.2241], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 9, Batch 1700] Loss: 1.910644\n",
      "Sample outputs: tensor([ 0.0003, -0.0413,  0.0131,  0.0224,  0.0626], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 9, Batch 1800] Loss: 1.913071\n",
      "Sample outputs: tensor([ 0.2163,  0.7211, -0.6815,  0.0730, -0.0645], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 9, Batch 1900] Loss: 1.887463\n",
      "Sample outputs: tensor([-0.3579, -0.0119, -0.6454, -0.2521,  0.2299], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 9, Batch 2000] Loss: 1.902705\n",
      "Sample outputs: tensor([ 0.0288, -0.1278, -0.2451, -0.0312,  0.1164], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 9, Batch 2100] Loss: 1.905722\n",
      "Sample outputs: tensor([ 0.2300,  0.2447, -0.2826, -0.1571, -0.0647], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "Epoch 9 Validation Loss: 6.443535\n",
      "[Epoch 10, Batch 100] Loss: 1.895819\n",
      "Sample outputs: tensor([ 0.0349, -0.1853, -0.5070, -0.3345,  0.2165], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 10, Batch 200] Loss: 1.894549\n",
      "Sample outputs: tensor([-0.4904,  0.2095, -0.0814,  0.1320,  0.1935], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 10, Batch 300] Loss: 1.908225\n",
      "Sample outputs: tensor([ 0.2866,  0.2291, -0.7577,  0.4208,  0.2891], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 10, Batch 400] Loss: 1.891951\n",
      "Sample outputs: tensor([-0.0891,  0.0306, -0.4402, -0.1926,  0.4870], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 10, Batch 500] Loss: 1.913863\n",
      "Sample outputs: tensor([ 0.5771, -0.1253, -0.3512, -0.6926, -0.1544], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 10, Batch 600] Loss: 1.906379\n",
      "Sample outputs: tensor([ 0.1127,  0.2716, -0.0155, -0.1068, -0.2309], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 10, Batch 700] Loss: 1.915179\n",
      "Sample outputs: tensor([-0.2685,  0.1904, -0.4637,  0.4165,  0.5040], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 10, Batch 800] Loss: 1.857449\n",
      "Sample outputs: tensor([ 0.1954, -0.3614, -0.3087, -0.9677,  0.7839], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 10, Batch 900] Loss: 1.909868\n",
      "Sample outputs: tensor([ 0.0465, -0.0238, -1.1455, -0.3794,  0.1588], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 10, Batch 1000] Loss: 1.848924\n",
      "Sample outputs: tensor([ 0.0415,  0.3569, -1.1682, -0.2537,  0.0966], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 10, Batch 1100] Loss: 1.933719\n",
      "Sample outputs: tensor([ 0.0817, -0.0137, -0.3057, -0.0918,  0.1008], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 10, Batch 1200] Loss: 1.925962\n",
      "Sample outputs: tensor([ 0.0081,  0.2939, -0.4350, -0.0852,  0.4133], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 10, Batch 1300] Loss: 1.919035\n",
      "Sample outputs: tensor([ 0.2212,  0.1112, -0.0756, -0.1090,  0.5519], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 10, Batch 1400] Loss: 1.932645\n",
      "Sample outputs: tensor([-0.2250, -0.0486,  0.2547, -0.3651,  0.2334], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 10, Batch 1500] Loss: 1.903030\n",
      "Sample outputs: tensor([-0.5762, -0.0463, -0.1509, -0.0473,  0.4948], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 10, Batch 1600] Loss: 1.911958\n",
      "Sample outputs: tensor([ 0.3946,  0.2554, -0.1164, -0.6568,  0.2595], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 10, Batch 1700] Loss: 1.890629\n",
      "Sample outputs: tensor([-0.0564, -0.1762, -0.2913,  0.2627,  0.0618], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 10, Batch 1800] Loss: 1.887730\n",
      "Sample outputs: tensor([ 0.6842, -0.2742, -0.1452, -0.2020,  0.2575], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 10, Batch 1900] Loss: 1.895261\n",
      "Sample outputs: tensor([ 0.2165,  0.0724, -0.3474, -0.2540,  0.2002], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 10, Batch 2000] Loss: 1.887902\n",
      "Sample outputs: tensor([ 0.1350,  0.0251, -0.1712, -0.5442,  0.2906], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 10, Batch 2100] Loss: 1.893294\n",
      "Sample outputs: tensor([ 0.3424, -0.5689,  0.1112, -0.5879,  0.4631], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "Epoch 10 Validation Loss: 4.060951\n",
      "[Epoch 11, Batch 100] Loss: 1.894632\n",
      "Sample outputs: tensor([ 0.0536, -0.3932, -0.8313, -0.1161,  0.4724], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 11, Batch 200] Loss: 1.900108\n",
      "Sample outputs: tensor([-0.1281,  0.0148, -0.4182, -0.3659,  0.5837], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 11, Batch 300] Loss: 1.899654\n",
      "Sample outputs: tensor([-0.3588,  0.1637, -0.1323, -0.2811,  0.5629], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 11, Batch 400] Loss: 1.887730\n",
      "Sample outputs: tensor([-0.4796, -0.1288,  0.0737, -0.6773,  0.0533], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 11, Batch 500] Loss: 1.888366\n",
      "Sample outputs: tensor([ 0.4897,  0.0373, -0.8913,  0.0299,  0.3171], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 11, Batch 600] Loss: 1.895901\n",
      "Sample outputs: tensor([ 0.0037,  0.4859, -0.6546, -0.1875,  0.4388], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 11, Batch 700] Loss: 1.901983\n",
      "Sample outputs: tensor([-0.2306,  0.3077,  0.0536, -0.2505,  0.0723], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 11, Batch 800] Loss: 1.889736\n",
      "Sample outputs: tensor([ 0.3450, -0.3244, -1.0973,  0.0170,  0.3190], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 11, Batch 900] Loss: 1.897190\n",
      "Sample outputs: tensor([-0.2660, -0.2275, -0.2159, -0.4011,  0.5236], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 11, Batch 1000] Loss: 1.910282\n",
      "Sample outputs: tensor([ 0.0263,  0.1957, -0.1429, -0.1523,  0.0247], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 11, Batch 1100] Loss: 1.896778\n",
      "Sample outputs: tensor([-0.0045,  0.3581, -0.6842,  0.0440,  0.4322], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 11, Batch 1200] Loss: 1.919488\n",
      "Sample outputs: tensor([-0.0087,  0.2937, -0.4275, -0.1293,  0.1644], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 11, Batch 1300] Loss: 1.913131\n",
      "Sample outputs: tensor([ 0.1358,  0.0648, -0.5840,  0.0382,  0.1379], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 11, Batch 1400] Loss: 1.911609\n",
      "Sample outputs: tensor([-0.1253,  0.3033, -0.9497, -0.1268,  0.2183], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 11, Batch 1500] Loss: 1.861456\n",
      "Sample outputs: tensor([ 0.1057, -0.1899, -0.8078, -0.4121,  0.6608], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 11, Batch 1600] Loss: 1.890793\n",
      "Sample outputs: tensor([ 0.1356, -0.0952, -0.0307, -0.3382,  0.5854], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 11, Batch 1700] Loss: 1.890540\n",
      "Sample outputs: tensor([-0.1819,  0.1362,  0.3560,  0.0738,  0.4789], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 11, Batch 1800] Loss: 1.922714\n",
      "Sample outputs: tensor([ 0.1972,  0.3415,  0.2227, -0.4161, -0.3440], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 11, Batch 1900] Loss: 1.917632\n",
      "Sample outputs: tensor([ 0.0297,  0.2478, -0.4700, -0.3429,  0.0989], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 11, Batch 2000] Loss: 1.900746\n",
      "Sample outputs: tensor([ 0.6252,  0.3500, -0.3668,  0.1367,  0.0980], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 11, Batch 2100] Loss: 1.898301\n",
      "Sample outputs: tensor([ 0.1037,  0.3079, -0.2006, -0.6096, -0.0516], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "Epoch 11 Validation Loss: 8.545903\n",
      "[Epoch 12, Batch 100] Loss: 1.899440\n",
      "Sample outputs: tensor([-0.5906, -0.0525,  0.4794,  0.1149,  0.1654], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 12, Batch 200] Loss: 1.936303\n",
      "Sample outputs: tensor([-0.0442, -0.6393, -0.0646,  0.1212,  0.0049], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 12, Batch 300] Loss: 1.910436\n",
      "Sample outputs: tensor([ 0.3733,  0.1345, -0.3096,  0.3569, -0.1626], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 12, Batch 400] Loss: 1.905405\n",
      "Sample outputs: tensor([-0.1150,  0.3749, -0.6763, -0.2159,  0.0499], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 12, Batch 500] Loss: 1.908414\n",
      "Sample outputs: tensor([ 0.1183, -0.0280, -0.3194, -0.0876,  0.0529], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 12, Batch 600] Loss: 1.914607\n",
      "Sample outputs: tensor([ 0.1552,  0.0625, -0.1174, -0.3776,  0.5079], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 12, Batch 700] Loss: 1.876439\n",
      "Sample outputs: tensor([ 0.6672,  0.2572, -0.5417, -0.5460, -0.0039], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 12, Batch 800] Loss: 1.916569\n",
      "Sample outputs: tensor([-0.3937, -0.1091, -0.1800,  0.0730, -0.2454], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 12, Batch 900] Loss: 1.907076\n",
      "Sample outputs: tensor([ 0.2573,  0.1643,  0.4464, -0.1134,  0.0851], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 12, Batch 1000] Loss: 1.884575\n",
      "Sample outputs: tensor([-0.0757,  0.0651, -0.4945, -0.1532, -0.0199], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 12, Batch 1100] Loss: 1.913448\n",
      "Sample outputs: tensor([ 0.2898, -0.2982, -0.1561, -0.1503,  0.2926], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 12, Batch 1200] Loss: 1.901802\n",
      "Sample outputs: tensor([ 0.2751,  0.3604, -0.3358, -0.0164,  0.1949], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 12, Batch 1300] Loss: 1.905526\n",
      "Sample outputs: tensor([ 0.2796,  0.2448, -0.5389,  0.2838,  0.4640], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 12, Batch 1400] Loss: 1.860620\n",
      "Sample outputs: tensor([-0.2047, -0.2243, -0.0726, -0.1229,  0.4665], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 12, Batch 1500] Loss: 1.890448\n",
      "Sample outputs: tensor([ 0.2597, -0.0050, -0.8191,  0.0039,  0.3380], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 12, Batch 1600] Loss: 1.887947\n",
      "Sample outputs: tensor([ 0.6308, -0.3726, -0.7341, -0.0224, -0.0953], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 12, Batch 1700] Loss: 1.910426\n",
      "Sample outputs: tensor([ 0.1061, -0.1276,  0.1623, -0.3616,  0.6810], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 12, Batch 1800] Loss: 1.920902\n",
      "Sample outputs: tensor([ 5.7352e-01, -4.6168e-04, -4.7978e-01, -1.1417e-02,  9.8715e-02],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 12, Batch 1900] Loss: 1.900763\n",
      "Sample outputs: tensor([ 0.1862, -0.2306, -0.2341, -0.2373,  0.2101], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 12, Batch 2000] Loss: 1.900697\n",
      "Sample outputs: tensor([-0.1266, -0.1472, -0.0741, -0.2668,  0.3792], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 12, Batch 2100] Loss: 1.911153\n",
      "Sample outputs: tensor([-0.1183, -0.3611, -0.9201,  0.4823,  0.3157], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "Epoch 12 Validation Loss: 6.316579\n",
      "[Epoch 13, Batch 100] Loss: 1.924888\n",
      "Sample outputs: tensor([0.1438, 0.0911, 0.0902, 0.0855, 0.0120], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 13, Batch 200] Loss: 1.887350\n",
      "Sample outputs: tensor([-0.0331, -0.3486, -0.7212, -0.2712,  0.4451], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 13, Batch 300] Loss: 1.847210\n",
      "Sample outputs: tensor([-0.0399,  0.2650, -0.6520, -0.4160,  0.4458], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 13, Batch 400] Loss: 1.947840\n",
      "Sample outputs: tensor([ 0.6673, -0.5052, -0.6983, -0.0302,  0.0982], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 13, Batch 500] Loss: 1.886534\n",
      "Sample outputs: tensor([-0.0028,  0.1806, -1.1234,  0.1567, -0.1797], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 13, Batch 600] Loss: 1.914504\n",
      "Sample outputs: tensor([ 0.1341,  0.1974, -0.1000, -0.3263,  0.3270], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 13, Batch 700] Loss: 1.904834\n",
      "Sample outputs: tensor([ 0.2533,  0.2331, -0.1119, -0.2113,  0.4559], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 13, Batch 800] Loss: 1.872332\n",
      "Sample outputs: tensor([-0.6538, -0.3448, -0.5181, -0.6868,  0.6374], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 13, Batch 900] Loss: 1.919516\n",
      "Sample outputs: tensor([ 0.0142, -0.4122, -0.5081, -0.5109,  0.0663], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 13, Batch 1000] Loss: 1.878210\n",
      "Sample outputs: tensor([ 0.3286, -0.3154, -0.4188,  0.3454,  0.7938], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 13, Batch 1100] Loss: 1.912832\n",
      "Sample outputs: tensor([ 0.6708,  0.2516, -0.0088,  0.3770, -0.3580], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 13, Batch 1200] Loss: 1.905627\n",
      "Sample outputs: tensor([-0.4325,  0.0297, -0.4016,  0.0242,  0.2236], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 13, Batch 1300] Loss: 1.924265\n",
      "Sample outputs: tensor([-0.0102,  0.1629, -0.5599,  0.1668,  0.1470], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 13, Batch 1400] Loss: 1.878100\n",
      "Sample outputs: tensor([-0.2129, -0.4519, -0.4310, -0.2570,  0.3726], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 13, Batch 1500] Loss: 1.915239\n",
      "Sample outputs: tensor([-0.3901, -0.2656, -0.4571,  0.5800, -0.2907], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 13, Batch 1600] Loss: 1.907244\n",
      "Sample outputs: tensor([ 0.3325,  0.2552, -0.7699, -0.4266,  0.6304], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 13, Batch 1700] Loss: 1.924374\n",
      "Sample outputs: tensor([-0.1671,  0.0976,  0.0120, -0.5012, -0.0428], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 13, Batch 1800] Loss: 1.922087\n",
      "Sample outputs: tensor([ 0.5443,  0.0396, -0.7420,  0.2381,  0.1002], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 13, Batch 1900] Loss: 1.887306\n",
      "Sample outputs: tensor([-0.0711,  0.4782, -0.3397, -0.6268, -0.2343], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 13, Batch 2000] Loss: 1.916158\n",
      "Sample outputs: tensor([-0.2266, -0.5423, -0.5869,  0.3408,  0.8241], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 13, Batch 2100] Loss: 1.889444\n",
      "Sample outputs: tensor([ 0.3810,  0.5896, -0.4609, -0.2929,  0.1174], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "Epoch 13 Validation Loss: 10.252043\n",
      "[Epoch 14, Batch 100] Loss: 1.863689\n",
      "Sample outputs: tensor([ 0.0965, -0.4380, -0.1945,  0.0909,  0.0843], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 14, Batch 200] Loss: 1.921973\n",
      "Sample outputs: tensor([ 0.1750,  0.4035, -0.7249, -0.1034,  0.0408], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 14, Batch 300] Loss: 1.907396\n",
      "Sample outputs: tensor([ 0.1116, -0.3741, -0.2159, -0.5221,  0.1651], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 14, Batch 400] Loss: 1.893909\n",
      "Sample outputs: tensor([ 0.5422, -0.0758, -0.2166, -0.7011, -0.0390], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 14, Batch 500] Loss: 1.945710\n",
      "Sample outputs: tensor([ 0.1850,  0.2861,  0.2758, -0.4192, -0.0692], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 14, Batch 600] Loss: 1.914497\n",
      "Sample outputs: tensor([ 0.1930,  0.6649, -0.8268,  0.0649, -0.1311], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 14, Batch 700] Loss: 1.896907\n",
      "Sample outputs: tensor([-0.0072, -0.3042, -0.3167, -0.0648,  0.3701], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 14, Batch 800] Loss: 1.927660\n",
      "Sample outputs: tensor([ 0.5585,  0.0598, -0.2487,  0.1262, -0.2439], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 14, Batch 900] Loss: 1.895089\n",
      "Sample outputs: tensor([ 0.3506, -0.1603, -0.1932, -0.3846,  0.3931], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 14, Batch 1000] Loss: 1.867657\n",
      "Sample outputs: tensor([ 0.3063, -0.2020, -0.7213, -0.3445,  0.3207], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 1\n",
      "[Epoch 14, Batch 1100] Loss: 1.911633\n",
      "Sample outputs: tensor([ 0.0530, -0.2436, -0.1662, -0.1817,  0.1586], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 14, Batch 1200] Loss: 1.932778\n",
      "Sample outputs: tensor([ 0.1922,  0.3083, -0.1815, -0.2904, -0.1018], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 14, Batch 1300] Loss: 1.911163\n",
      "Sample outputs: tensor([ 0.0804,  0.1173, -0.4854,  0.2065, -0.1171], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 14, Batch 1400] Loss: 1.904832\n",
      "Sample outputs: tensor([-0.1320,  0.2223, -1.0426,  0.0911,  0.4225], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 14, Batch 1500] Loss: 1.884996\n",
      "Sample outputs: tensor([ 0.0332,  0.4191, -0.9384, -0.1901,  0.4793], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 14, Batch 1600] Loss: 1.920542\n",
      "Sample outputs: tensor([ 0.0110,  0.2082, -0.3996,  0.1413,  0.4560], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 14, Batch 1700] Loss: 1.889523\n",
      "Sample outputs: tensor([-0.1775, -0.0008, -0.5567, -0.1056,  0.1800], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 14, Batch 1800] Loss: 1.934334\n",
      "Sample outputs: tensor([ 0.0667, -0.0874,  0.2831, -0.0700,  0.2008], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 14, Batch 1900] Loss: 1.865491\n",
      "Sample outputs: tensor([-0.4117,  0.1450, -0.2214, -0.0277,  0.4522], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 14, Batch 2000] Loss: 1.904983\n",
      "Sample outputs: tensor([ 0.4944,  0.1343,  0.3344, -0.2252, -0.5407], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 14, Batch 2100] Loss: 1.895706\n",
      "Sample outputs: tensor([ 0.1762, -0.4841, -0.2122, -0.2357,  0.3141], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "Epoch 14 Validation Loss: 4.841408\n",
      "[Epoch 15, Batch 100] Loss: 1.912896\n",
      "Sample outputs: tensor([-0.5049, -0.4205, -0.6463, -0.2486,  0.2999], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 15, Batch 200] Loss: 1.905265\n",
      "Sample outputs: tensor([ 0.1943, -0.0676, -0.2404, -0.0711,  0.2485], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 15, Batch 300] Loss: 1.889874\n",
      "Sample outputs: tensor([-0.1468, -0.1928, -0.4530,  0.2547,  0.0946], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 15, Batch 400] Loss: 1.879575\n",
      "Sample outputs: tensor([-0.0825,  0.2106,  0.0322, -0.8786,  0.2868], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 15, Batch 500] Loss: 1.904380\n",
      "Sample outputs: tensor([ 0.1426, -0.6093,  0.3045,  0.3270,  0.1385], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 15, Batch 600] Loss: 1.885907\n",
      "Sample outputs: tensor([ 0.4843, -0.1844, -0.3868, -0.3885,  0.4298], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 15, Batch 700] Loss: 1.917508\n",
      "Sample outputs: tensor([-0.2833,  0.1661, -0.2287,  0.1119,  0.4637], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 15, Batch 800] Loss: 1.861104\n",
      "Sample outputs: tensor([-0.2464,  0.6127, -0.3204, -0.5269, -0.0488], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 6\n",
      "[Epoch 15, Batch 900] Loss: 1.928616\n",
      "Sample outputs: tensor([ 0.0791,  0.1551, -0.9427, -0.5550,  0.4904], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 2\n",
      "[Epoch 15, Batch 1000] Loss: 1.899657\n",
      "Sample outputs: tensor([ 0.4108,  0.1527,  0.0894, -0.2769, -0.6310], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "[Epoch 15, Batch 1100] Loss: 1.892974\n",
      "Sample outputs: tensor([ 0.1629, -0.4863, -0.1447, -0.5062,  0.6202], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 9\n",
      "[Epoch 15, Batch 1200] Loss: 1.881625\n",
      "Sample outputs: tensor([-0.1110,  0.6497, -0.5925, -0.0888,  0.7071], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 15, Batch 1300] Loss: 1.926544\n",
      "Sample outputs: tensor([-0.0769,  0.0892, -0.2845, -0.3264,  0.5528], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 15, Batch 1400] Loss: 1.919246\n",
      "Sample outputs: tensor([-0.1299, -0.0140, -0.2195,  0.3024, -0.1368], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 15, Batch 1500] Loss: 1.910541\n",
      "Sample outputs: tensor([-0.1509,  0.1483,  0.0427,  0.0569,  0.1438], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 7\n",
      "[Epoch 15, Batch 1600] Loss: 1.883139\n",
      "Sample outputs: tensor([ 0.5941, -0.0085, -0.2926, -0.0354, -0.1389], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 8\n",
      "[Epoch 15, Batch 1700] Loss: 1.892863\n",
      "Sample outputs: tensor([ 0.4105,  0.3364, -0.4796, -0.4716, -0.2637], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 3\n",
      "[Epoch 15, Batch 1800] Loss: 1.900999\n",
      "Sample outputs: tensor([-0.1112, -0.2194, -0.3935,  0.0200,  0.1429], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 4\n",
      "[Epoch 15, Batch 1900] Loss: 1.916577\n",
      "Sample outputs: tensor([-0.2307,  0.2174, -0.2419,  0.3375, -0.1824], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 15, Batch 2000] Loss: 1.929630\n",
      "Sample outputs: tensor([ 0.0748, -0.1521, -0.3006, -0.0120,  0.2151], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 5\n",
      "[Epoch 15, Batch 2100] Loss: 1.894513\n",
      "Sample outputs: tensor([ 0.0451,  0.3071, -0.5659,  0.3106,  0.0437], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n",
      "Sample labels: 0\n",
      "Epoch 15 Validation Loss: 6.689856\n",
      "Early stopping triggered after 15 epochs\n",
      "Finished Training\n",
      "Model saved to --HistoryManager.hist_file=:memory:\n",
      "Accuracy on the test set: 13.55%\n"
     ]
    }
   ],
   "source": [
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model instance\n",
    "model = birdClassifier().to(device)\n",
    "print(\"Model created and moved to device\")\n",
    "# Set up loss function and optimizer\n",
    "criterion = FocalLoss(alpha=1, gamma=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# Train the model with early stopping\n",
    "model = train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=60,\n",
    "    patience=5,\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), modelPath)\n",
    "print(f\"Model saved to {modelPath}\")\n",
    "# hello world\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5837237,
     "sourceId": 9575326,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5928001,
     "sourceId": 9695725,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2745.759525,
   "end_time": "2024-10-23T07:54:28.778106",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-23T07:08:43.018581",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
